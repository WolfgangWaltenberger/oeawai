{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amarafioti/.local/lib/python3.5/site-packages/numba/errors.py:131: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269776\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import librosa\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from trainDataset import TrainDataset\n",
    "from testDataset import TestDataset\n",
    "\n",
    "toFloat = transforms.Lambda(lambda x: x / np.iinfo(np.int16).max)\n",
    "\n",
    "trainDataset = TrainDataset(\"kaggle-train\", transform=toFloat)\n",
    "print(len(trainDataset))\n",
    "\n",
    "testDataset = TestDataset(\"kaggle-test\", transform=toFloat)\n",
    "print(len(testDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the SVM took 18.701761484146118mins\n"
     ]
    }
   ],
   "source": [
    "familyClassifier = svm.SVC()\n",
    "\n",
    "trainLoader = data.DataLoader(trainDataset, batch_size=6400, shuffle=True)\n",
    "start = time.time()\n",
    "for samples, instrumentsFamily in trainLoader:\n",
    "    familyClassifier.fit(np.array(samples.data)[:, :16000], np.array(instrumentsFamily.data))\n",
    "    break # SVM is only fitted to a fixed size of data\n",
    "print(\"Fitting the SVM took \" + str((time.time()-start)/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying took 7.246222802003225mins\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "testloader = data.DataLoader(testDataset, batch_size=batch_size, shuffle=False) #!!! Shuffle should be false\n",
    "\n",
    "familyPredictions = np.zeros(len(testDataset), dtype=np.int)\n",
    "start = time.time()\n",
    "for index, samples in enumerate(testloader):\n",
    "    familyPredictions[index*batch_size:(index+1)*batch_size] = familyClassifier.predict(np.array(samples.data)[:, :16000])\n",
    "print(\"Classifying took \" + str((time.time()-start)/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amarafioti/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "familyPredictionStrings = trainDataset.transformInstrumentsFamilyToString(familyPredictions.astype(int))\n",
    "\n",
    "with open('SVM-time-submission.csv', 'w', newline='') as writeFile:\n",
    "    fieldnames = ['Id', 'Expected']\n",
    "    writer = csv.DictWriter(writeFile, fieldnames=fieldnames, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writeheader()\n",
    "    for index in range(len(testDataset)):\n",
    "        writer.writerow({'Id': index, 'Expected': familyPredictionStrings[index]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what we can do with a more informed SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the SVM took 1.5752114375432333mins\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 16000\n",
    "\n",
    "informedFamilyClassifier = svm.SVC()\n",
    "\n",
    "def computeMelspectrogram(numpyArray, sample_rate):\n",
    "    S = librosa.feature.melspectrogram(y=numpyArray, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "    return np.log(S+1e-4)\n",
    "\n",
    "trainLoader = data.DataLoader(trainDataset, batch_size=6400, shuffle=True)\n",
    "start = time.time()\n",
    "for samples, instrumentsFamily in trainLoader:\n",
    "    mfccs = np.zeros((len(samples), 128))\n",
    "    for index, sample in enumerate(samples.data):\n",
    "        mfccs[index] = np.mean(computeMelspectrogram(sample.numpy(), sample_rate), axis=1)\n",
    "\n",
    "    informedFamilyClassifier.fit(mfccs, instrumentsFamily.numpy())\n",
    "    break # SVM is only fitted to a fixed size of data\n",
    "print(\"Fitting the SVM took \" + str((time.time()-start)/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying took 0.737498418490092mins\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "testloader = data.DataLoader(testDataset, batch_size=batch_size, shuffle=False) #!!! Shuffle should be false\n",
    "\n",
    "informedFamilyPredictions = np.zeros(len(testDataset), dtype=np.int)\n",
    "start = time.time()\n",
    "for index, samples in enumerate(testloader):\n",
    "    mfccs = np.zeros((len(samples), 128))\n",
    "    for inner_index, sample in enumerate(samples.data):\n",
    "        mfccs[inner_index] = np.mean(computeMelspectrogram(sample.numpy(), sample_rate), axis=1)\n",
    "\n",
    "    informedFamilyPredictions[index*batch_size:(index+1)*batch_size] = informedFamilyClassifier.predict(mfccs)\n",
    "print(\"Classifying took \" + str((time.time()-start)/60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amarafioti/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "informedFamilyPredictionStrings = trainDataset.transformInstrumentsFamilyToString(informedFamilyPredictions.astype(int))\n",
    "\n",
    "with open('SVM-informed-submission.csv', 'w', newline='') as writeFile:\n",
    "    fieldnames = ['Id', 'Expected']\n",
    "    writer = csv.DictWriter(writeFile, fieldnames=fieldnames, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writeheader()\n",
    "    for index in range(len(testDataset)):\n",
    "        writer.writerow({'Id': index, 'Expected': informedFamilyPredictionStrings[index]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(32):\n",
    "    plt.plot(mfccs[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
